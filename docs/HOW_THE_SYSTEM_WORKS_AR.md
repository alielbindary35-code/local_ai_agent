# ğŸ“š Ø´Ø±Ø­ Ù†Ø¸Ø§Ù… Ø§Ù„Ù€ AI Agent - Ø¯Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„

## Ù†Ø¸Ø±Ø© Ø¹Ø§Ù…Ø© Ø¹Ù„Ù‰ Ø§Ù„Ù†Ø¸Ø§Ù…

Ù†Ø¸Ø§Ù… AI Agent Ù…Ø­Ù„ÙŠ ÙŠØ¹Ù…Ù„ Ø¹Ù„Ù‰ Ollama ÙˆÙŠØªÙƒÙˆÙ† Ù…Ù† 3 Ù…Ø³ØªÙˆÙŠØ§Øª:

- **Simple Agent**: Ø¨Ø³ÙŠØ· ÙˆØ³Ø±ÙŠØ¹ (22 Ø£Ø¯Ø§Ø©ØŒ Ù…ÙˆØ¯ÙŠÙ„ ÙˆØ§Ø­Ø¯)
- **Standard Agent**: Ù…ØªÙˆØ³Ø· (22 Ø£Ø¯Ø§Ø©ØŒ ReAct loop ÙƒØ§Ù…Ù„)
- **Expert Agent**: Ø§Ø­ØªØ±Ø§ÙÙŠ (67+ Ø£Ø¯Ø§Ø©ØŒ Ø§Ø®ØªÙŠØ§Ø± ØªÙ„Ù‚Ø§Ø¦ÙŠ Ù„Ù„Ù…ÙˆØ¯ÙŠÙ„) â­

---

## Ø§Ù„Ø¨Ù†ÙŠØ© Ø§Ù„Ù…Ø¹Ù…Ø§Ø±ÙŠØ© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©

### 1. Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©

```
ExpertAgent (src/agents/expert_agent.py)
â”œâ”€â”€ Tools (src/tools/tools.py) - 22 Ø£Ø¯Ø§Ø© Ø£Ø³Ø§Ø³ÙŠØ©
â”œâ”€â”€ ExpertTools (src/tools/expert_tools.py) - 45+ Ø£Ø¯Ø§Ø© Ù…ØªØ®ØµØµØ©
â”œâ”€â”€ ExtendedTools (src/tools/extended_tools.py) - Ø£Ø¯ÙˆØ§Øª Ø¥Ø¶Ø§ÙÙŠØ©
â”œâ”€â”€ Memory (src/core/memory.py) - Ù†Ø¸Ø§Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø© SQLite
â””â”€â”€ AutoLearner (src/tools/auto_learner.py) - Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ
```

### 2. ØªØ¯ÙÙ‚ Ø§Ù„Ø¹Ù…Ù„ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ

```
User Input â†’ Task Detection â†’ Model Selection â†’ ReAct Loop â†’ Tool Execution â†’ Response
```

---

## Ø¢Ù„ÙŠØ© Ø¹Ù…Ù„ Expert Agent (Ø§Ù„Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠ)

### Ø§Ù„Ù…Ø±Ø­Ù„Ø© 1: Ø§Ù„ØªÙ‡ÙŠØ¦Ø© (Initialization)

**Ø§Ù„Ù…Ù„Ù**: `src/agents/expert_agent.py` - Ø¯Ø§Ù„Ø© `__init__`

#### 1.1 Ø¬Ù„Ø¨ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©

Ø¹Ù†Ø¯ Ø¨Ø¯Ø¡ ØªØ´ØºÙŠÙ„ Ø§Ù„Ù€ AgentØŒ ÙŠÙ‚ÙˆÙ… Ø¨Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø§Ù„ØªØ§Ù„ÙŠØ©:

```python
def _get_available_models(self) -> List[Dict[str, Any]]:
    """Get list of available models with their specs"""
    try:
        response = requests.get(f"{self.ollama_url}/api/tags")
        if response.status_code == 200:
            models = response.json().get('models', [])
            return [{
                'name': m['name'],
                'size': m.get('size', 0),
                'modified': m.get('modified_at', '')
            } for m in models]
        return []
    except Exception as e:
        console.print(f"[yellow]Warning: Could not fetch models: {e}[/yellow]")
        return []
```

**Ù…Ø§ ÙŠØ­Ø¯Ø«**:
- ÙŠØ±Ø³Ù„ Ø·Ù„Ø¨ GET Ø¥Ù„Ù‰ `http://localhost:11434/api/tags`
- ÙŠØ­ØµÙ„ Ø¹Ù„Ù‰ Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„Ø§Øª Ø§Ù„Ù…Ø«Ø¨ØªØ© ÙÙŠ Ollama
- ÙŠØ­ÙØ¸ Ø§Ø³Ù… Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ØŒ Ø§Ù„Ø­Ø¬Ù…ØŒ ÙˆØªØ§Ø±ÙŠØ® Ø§Ù„ØªØ¹Ø¯ÙŠÙ„

#### 1.2 ØªØ­Ù„ÙŠÙ„ Ù‚Ø¯Ø±Ø§Øª Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„Ø§Øª

```python
def _analyze_model_capabilities(self) -> Dict[str, Dict]:
    """Analyze capabilities of each model"""
    capabilities = {}
    
    for model in self.available_models:
        name = model['name']
        size = model.get('size', 0)
        
        # Determine capabilities based on model name and size
        caps = {
            'speed': 'fast',
            'accuracy': 'medium',
            'specialization': 'general',
            'best_for': []
        }
        
        # DeepSeek models - best for coding
        if 'deepseek' in name.lower():
            caps['specialization'] = 'coding'
            caps['accuracy'] = 'high'
            caps['best_for'] = ['programming', 'debugging', 'code_review', 'architecture']
        
        # Qwen models - balanced, good for reasoning
        elif 'qwen' in name.lower():
            if '0.5b' in name:
                caps['speed'] = 'very_fast'
                caps['accuracy'] = 'low'
                caps['best_for'] = ['simple_queries', 'quick_answers']
            elif '3b' in name:
                caps['speed'] = 'fast'
                caps['accuracy'] = 'medium'
                caps['best_for'] = ['general_tasks', 'file_operations', 'system_info']
            else:
                caps['accuracy'] = 'high'
                caps['best_for'] = ['complex_reasoning', 'analysis', 'planning']
        
        # Llama models - good for general tasks
        elif 'llama' in name.lower():
            caps['specialization'] = 'general'
            caps['accuracy'] = 'high'
            caps['best_for'] = ['conversation', 'general_tasks', 'reasoning']
        
        capabilities[name] = caps
    
    return capabilities
```

**Ù…Ø§ ÙŠØ­Ø¯Ø«**:
- Ø¯Ø§Ù„Ø© `_analyze_model_capabilities()` ØªØ­Ù„Ù„ ÙƒÙ„ Ù…ÙˆØ¯ÙŠÙ„
- ØªØ­Ø¯Ø¯ Ø§Ù„ØªØ®ØµØµ (coding, general, conversation)
- ØªØ­Ø¯Ø¯ Ø§Ù„Ø³Ø±Ø¹Ø© ÙˆØ§Ù„Ø¯Ù‚Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø­Ø¬Ù… ÙˆØ§Ù„Ø§Ø³Ù…
- Ù…Ø«Ø§Ù„: `deepseek-r1:8b` â†’ ØªØ®ØµØµ: codingØŒ Ø¯Ù‚Ø©: high

#### 1.3 Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª

```python
def _display_initialization(self):
    """Display initialization info"""
    # Create models table
    table = Table(title="ğŸ¤– Available Models", show_header=True)
    table.add_column("Model", style="cyan")
    table.add_column("Size", style="green")
    table.add_column("Specialization", style="yellow")
    table.add_column("Best For", style="blue")
    
    for model in self.available_models:
        name = model['name']
        size_gb = model.get('size', 0) / 1_000_000_000
        caps = self.model_capabilities.get(name, {})
        
        table.add_row(
            name,
            f"{size_gb:.1f} GB",
            caps.get('specialization', 'general'),
            ', '.join(caps.get('best_for', ['general'])[:2])
        )
    
    console.print(table)
```

**Ù…Ø§ ÙŠØ­Ø¯Ø«**:
- ÙŠØ¹Ø±Ø¶ Ø¬Ø¯ÙˆÙ„ Ø¨Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©
- ÙŠØ¹Ø±Ø¶ Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ù…ØªØ§Ø­Ø© (67+)
- ÙŠØ¹Ø±Ø¶ Ø­Ø§Ù„Ø© Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø£ÙˆÙ†Ù„Ø§ÙŠÙ†

---

### Ø§Ù„Ù…Ø±Ø­Ù„Ø© 2: Ø§Ø³ØªÙ‚Ø¨Ø§Ù„ Ø§Ù„Ø·Ù„Ø¨ (User Request)

**Ø§Ù„Ù…Ù„Ù**: `src/agents/expert_agent.py` - Ø¯Ø§Ù„Ø© `run()`

Ø¹Ù†Ø¯Ù…Ø§ ÙŠØ±Ø³Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø·Ù„Ø¨Ø§Ù‹:

#### 2.1 Ø¹Ø±Ø¶ Ø§Ù„Ø·Ù„Ø¨

```python
def run(self, user_input: str, task_type: str = None) -> str:
    """Run the expert agent with tool execution loop"""
    console.print(Panel(
        f"[bold cyan]{user_input}[/bold cyan]",
        title="ğŸ¯ Expert Task",
        border_style="cyan"
    ))
```

**Ù…Ø§ ÙŠØ­Ø¯Ø«**:
- ÙŠØ¹Ø±Ø¶ Ø§Ù„Ø·Ù„Ø¨ ÙÙŠ Panel Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Rich library

#### 2.2 ÙƒØ´Ù Ù†ÙˆØ¹ Ø§Ù„Ù…Ù‡Ù…Ø© (Task Type Detection)

```python
def _detect_task_type(self, task_description: str) -> str:
    """Detect task type from description"""
    task_lower = task_description.lower()
    
    # Coding keywords
    if any(word in task_lower for word in ['code', 'program', 'function', 'class', 'debug', 'python', 'javascript', 'java', 'c++', 'algorithm']):
        return 'coding'
    
    # Web design keywords
    if any(word in task_lower for word in ['website', 'web', 'html', 'css', 'frontend', 'backend', 'ui', 'ux', 'design']):
        return 'web_design'
    
    # Server/DevOps keywords
    if any(word in task_lower for word in ['server', 'deploy', 'nginx', 'apache', 'linux', 'ubuntu', 'centos']):
        return 'server'
    
    # Docker keywords
    if any(word in task_lower for word in ['docker', 'container', 'dockerfile', 'compose', 'kubernetes', 'k8s']):
        return 'docker'
    
    # Database keywords
    if any(word in task_lower for word in ['database', 'sql', 'postgres', 'postgresql', 'mysql', 'mongodb', 'query']):
        return 'database'
    
    # n8n keywords
    if any(word in task_lower for word in ['n8n', 'workflow', 'automation', 'integration']):
        return 'automation'
    
    # Simple tasks
    if any(word in task_lower for word in ['what is', 'show', 'list', 'get', 'check', 'find']):
        return 'simple'
    
    return 'general'
```

**Ù…Ø§ ÙŠØ­Ø¯Ø«**:
- Ø¯Ø§Ù„Ø© `_detect_task_type()` ØªØ­Ù„Ù„ Ø§Ù„Ù†Øµ
- ØªØ¨Ø­Ø« Ø¹Ù† ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ©:
  - `coding`: code, program, function, python, javascript
  - `web_design`: website, html, css, frontend
  - `server`: server, deploy, nginx, linux
  - `docker`: docker, container, dockerfile, compose
  - `database`: database, sql, postgres, mysql
  - `simple`: what is, show, list, get

#### 2.3 Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨

```python
def _select_best_model(self, task_description: str, task_type: str = None) -> str:
    """Intelligently select the best model for the task"""
    if not self.available_models:
        return "qwen2.5:3b"  # Fallback
    
    # Auto-detect task type if not provided
    if not task_type:
        task_type = self._detect_task_type(task_description)
    
    console.print(f"[dim]ğŸ¯ Detected task type: {task_type}[/dim]")
    
    # Scoring system for model selection
    scores = {}
    
    for model in self.available_models:
        name = model['name']
        caps = self.model_capabilities.get(name, {})
        score = 0
        
        # Task-specific scoring
        if task_type == 'coding' or task_type == 'programming':
            if 'deepseek' in name.lower():
                score += 100  # DeepSeek is best for coding
            elif 'qwen' in name.lower() and '3b' not in name:
                score += 50
        
        elif task_type == 'web_design':
            if 'deepseek' in name.lower():
                score += 80
            elif 'qwen' in name.lower():
                score += 60
        
        elif task_type in ['server', 'docker', 'database', 'devops']:
            if 'deepseek' in name.lower():
                score += 90
            elif 'llama' in name.lower():
                score += 70
            elif 'mistral' in name.lower():
                score += 75
        
        elif task_type == 'simple':
            if '0.5b' in name or '3b' in name:
                score += 100  # Small models for simple tasks
        
        else:  # general tasks
            if 'mistral' in name.lower():
                score += 80
            elif 'llama' in name.lower():
                score += 75
            elif 'qwen' in name.lower() and '3b' not in name:
                score += 70
        
        # Size bonus (prefer larger models for complex tasks)
        size = model.get('size', 0)
        if task_type in ['coding', 'web_design', 'server', 'docker', 'database']:
            if size > 4_000_000_000:  # > 4GB
                score += 30
            elif size > 2_000_000_000:  # > 2GB
                score += 15
        
        scores[name] = score
    
    # Select model with highest score
    best_model = max(scores, key=scores.get)
    best_score = scores[best_model]
    
    console.print(f"[cyan]ğŸ¤– Selected model:[/cyan] [bold]{best_model}[/bold] (score: {best_score})")
    console.print(f"[dim]Reason: {self.model_capabilities.get(best_model, {}).get('specialization', 'general')} specialist[/dim]")
    
    return best_model
```

**Ù†Ø¸Ø§Ù… Scoring**:
```
Ø¥Ø°Ø§ task_type == 'coding':
    deepseek-r1:8b: +100 (Ù…ØªØ®ØµØµ ÙÙŠ Ø§Ù„Ø¨Ø±Ù…Ø¬Ø©)
    qwen2.5:8b: +50
    mistral:latest: +30

Ø¥Ø°Ø§ task_type == 'simple':
    qwen2.5:0.5b: +100 (ØµØºÙŠØ± ÙˆØ³Ø±ÙŠØ¹)
    qwen2.5:3b: +80

Ø¥Ø°Ø§ task_type == 'docker' Ø£Ùˆ 'server':
    deepseek-r1:8b: +90
    llama3.2:latest: +70
```

**Ù…Ø§ ÙŠØ­Ø¯Ø«**:
- Ø¯Ø§Ù„Ø© `_select_best_model()` ØªØ­Ø³Ø¨ Score Ù„ÙƒÙ„ Ù…ÙˆØ¯ÙŠÙ„
- ÙŠØ®ØªØ§Ø± Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø¨Ø£Ø¹Ù„Ù‰ Score

---

### Ø§Ù„Ù…Ø±Ø­Ù„Ø© 3: Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù€ Prompt

**Ø§Ù„Ù…Ù„Ù**: `src/agents/expert_agent.py` - Ø¯Ø§Ù„Ø© `_build_expert_prompt()`

#### 3.1 Ø¬Ù…Ø¹ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø£Ø¯ÙˆØ§Øª

```python
def _build_expert_prompt(self, user_input: str, selected_model: str) -> str:
    """Build comprehensive prompt for expert agent"""
    
    # Get tool descriptions
    basic_tools = self.tools.get_tool_descriptions()
    expert_tools = self.expert_tools.get_tool_descriptions()
    extended_tools = self.extended_tools.get_tool_descriptions()
    
    all_tools = f"{basic_tools}\n\n{expert_tools}\n\n{extended_tools}"
```

**Ù…Ø§ ÙŠØ­Ø¯Ø«**:
- ÙŠØ¬Ù…Ø¹ Ø£ÙˆØµØ§Ù Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø¯ÙˆØ§Øª Ù…Ù†:
  - `tools.get_tool_descriptions()` (22 Ø£Ø¯Ø§Ø© Ø£Ø³Ø§Ø³ÙŠØ©)
  - `expert_tools.get_tool_descriptions()` (45+ Ø£Ø¯Ø§Ø© Ù…ØªØ®ØµØµØ©)
  - `extended_tools.get_tool_descriptions()` (Ø£Ø¯ÙˆØ§Øª Ø¥Ø¶Ø§ÙÙŠØ©)

#### 3.2 Ø¨Ù†Ø§Ø¡ System Prompt

```python
    prompt = f"""You are an Expert AI Agent with access to powerful tools.

Available Tools:
{all_tools}

How to use tools:
- Use JSON format: {{"tool": "tool_name", "args": ["arg1", "arg2"]}}
- You can call multiple tools in sequence
- Read tool results before making decisions

Task: {user_input}

Instructions:
1. Analyze the task
2. Plan your approach
3. Use appropriate tools
4. Provide final answer

Start by thinking about the task, then use tools as needed.
"""
```

**Ù…Ø§ ÙŠØ­Ø¯Ø«**:
- ÙŠØ´Ø±Ø­ Ù„Ù„Ù…ÙˆØ¯ÙŠÙ„:
  - Ù…Ø§ Ù‡ÙŠ Ø§Ù„Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©
  - ÙƒÙŠÙ ÙŠØ³ØªØ®Ø¯Ù…Ù‡Ø§ (JSON format)
  - Ø£Ù…Ø«Ù„Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
  - Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„Ø®Ø§ØµØ© Ø¨Ù†ÙˆØ¹ Ø§Ù„Ù…Ù‡Ù…Ø©

#### 3.3 Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø³ÙŠØ§Ù‚

```python
    # Add conversation history
    if self.conversation_history:
        prompt += "\n\nPrevious conversation:\n"
        for msg in self.conversation_history[-5:]:  # Last 5 messages
            prompt += f"- {msg}\n"
    
    # Add memory context if available
    similar_solutions = self.memory.search_similar(user_input)
    if similar_solutions:
        prompt += "\n\nSimilar past solutions:\n"
        for solution, rating in similar_solutions[:2]:
            prompt += f"- {solution[:200]}... (Rating: {rating}â­)\n"
```

**Ù…Ø§ ÙŠØ­Ø¯Ø«**:
- ÙŠØ¶ÙŠÙ ØªØ§Ø±ÙŠØ® Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚
- ÙŠØ¶ÙŠÙ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ù† Ø§Ù„Ø°Ø§ÙƒØ±Ø© (Ø¥Ù† ÙˆØ¬Ø¯Øª)

---

### Ø§Ù„Ù…Ø±Ø­Ù„Ø© 4: Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ (Model Call)

**Ø§Ù„Ù…Ù„Ù**: `src/agents/expert_agent.py` - Ø¯Ø§Ù„Ø© `_call_ollama()`

#### 4.1 Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø·Ù„Ø¨

```python
def _call_ollama(self, prompt: str, model: str, temperature: float = 0.7, use_fallback: bool = True) -> str:
    """Call Ollama API with streaming support"""
    try:
        url = f"{self.ollama_url}/api/generate"
        payload = {
            "model": model,
            "prompt": prompt,
            "stream": True,
            "temperature": temperature,
            "options": {
                "num_predict": 4000,
                "top_p": 0.9,
                "top_k": 40
            }
        }
        
        response = requests.post(url, json=payload, stream=True, timeout=300)
        response.raise_for_status()
```

**Ù…Ø§ ÙŠØ­Ø¯Ø«**:
- ÙŠØ±Ø³Ù„ POST request Ø¥Ù„Ù‰ `http://localhost:11434/api/generate`
- Body ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰:
  ```json
  {
    "model": "deepseek-r1:8b",
    "prompt": "...",
    "stream": true,
    "temperature": 0.7
  }
  ```

#### 4.2 Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø¯ Ø§Ù„Ù…ØªØ¯ÙÙ‚ (Streaming)

```python
        # Stream response
        full_response = ""
        tokens_received = 0
        start_time = time.time()
        
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            console=console
        ) as progress:
            task = progress.add_task(f"[cyan]Processing with {model}...", total=None)
            
            for line in response.iter_lines():
                if line:
                    try:
                        json_response = json.loads(line)
                        if 'response' in json_response:
                            token = json_response['response']
                            full_response += token
                            tokens_received += 1
                            
                            # Update progress
                            elapsed = time.time() - start_time
                            if elapsed > 0:
                                speed = tokens_received / elapsed
                                progress.update(
                                    task,
                                    description=f"[cyan]Processing... ({tokens_received} tokens @ {speed:.1f}/s, {elapsed:.0f}s elapsed)"
                                )
                        
                        if json_response.get('done', False):
                            break
                    except json.JSONDecodeError:
                        continue
```

**Ù…Ø§ ÙŠØ­Ø¯Ø«**:
- ÙŠØ³ØªÙ‚Ø¨Ù„ Ø§Ù„Ø±Ø¯ token Ø¨Ø¹Ø¯ token
- ÙŠØ¹Ø±Ø¶ Progress bar Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Rich
- ÙŠØ¬Ù…Ø¹ ÙƒÙ„ Ø§Ù„Ù€ tokens ÙÙŠ response ÙƒØ§Ù…Ù„

#### 4.3 Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ø®Ø·Ø§Ø¡

```python
        except requests.exceptions.Timeout:
            error_msg = "Error: Request timeout. Model may be overloaded or system resources are limited."
            console.print(f"[red]{error_msg}[/red]")
            
            if use_fallback:
                diagnostics = self._diagnose_ollama_issue()
                if diagnostics['issues']:
                    console.print("[red]Diagnostics:[/red]")
                    for issue in diagnostics['issues']:
                        console.print(f"  - {issue}")
                
                if use_fallback:
                    fallback_result = self._try_fallback_model(model, prompt, temperature)
                    if fallback_result:
                        return fallback_result
            
            return error_msg
```

**Ù…Ø§ ÙŠØ­Ø¯Ø«**:
- Ø¥Ø°Ø§ ÙØ´Ù„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ØŒ ÙŠØ­Ø§ÙˆÙ„ Fallback model
- ÙŠØ¹Ø±Ø¶ ØªØ´Ø®ÙŠØµ Ù„Ù„Ù…Ø´ÙƒÙ„Ø© (Diagnostics)

---

### Ø§Ù„Ù…Ø±Ø­Ù„Ø© 5: ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø±Ø¯ ÙˆØ§Ø³ØªØ®Ø±Ø§Ø¬ Tool Calls

**Ø§Ù„Ù…Ù„Ù**: `src/agents/expert_agent.py` - Ø¯Ø§Ù„Ø© `run()` (Ø¨Ø¹Ø¯ Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„)

#### 5.1 Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Tool Calls

```python
        # Try to find tool calls in the response
        import re
        
        # === STEP 1: Try to parse JSON-style tool calls first ===
        json_tool_calls = []
        try:
            # Look for JSON objects with "tool" and "args" fields
            potential_jsons = []
            brace_count = 0
            start_idx = -1
            
            for i, char in enumerate(response):
                if char == '{':
                    if brace_count == 0:
                        start_idx = i
                    brace_count += 1
                elif char == '}':
                    brace_count -= 1
                    if brace_count == 0 and start_idx != -1:
                        json_str = response[start_idx:i+1]
                        potential_jsons.append(json_str)
                        start_idx = -1
            
            # Now try to parse each potential JSON
            for json_str in potential_jsons:
                try:
                    data = json.loads(json_str)
                    if isinstance(data, dict) and "tool" in data and "args" in data:
                        tool_name = data["tool"]
                        args_list = data["args"]
                        if not isinstance(args_list, list):
                            args_list = [args_list]
                        json_tool_calls.append((tool_name, args_list))
                        console.print(f"[cyan]ğŸ“Š Status:[/cyan] [yellow]Found JSON tool call: {tool_name}[/yellow]")
                except (json.JSONDecodeError, KeyError):
                    continue
```

**Ù…Ø§ ÙŠØ­Ø¯Ø«**:
- ÙŠØ¨Ø­Ø« Ø¹Ù† JSON format ÙÙŠ Ø§Ù„Ø±Ø¯:
  ```json
  {
    "tool": "write_file",
    "args": ["filepath", "content"]
  }
  ```
- ÙŠØ³ØªØ®Ø¯Ù… regex Ùˆ JSON parsing Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Tool Calls

#### 5.2 Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ø£Ø¯Ø§Ø©

```python
        # === STEP 2: Execute JSON-style tool calls ===
        for tool_name, args_list in json_tool_calls:
            # Check if it's a valid tool
            if hasattr(self.tools, tool_name) or hasattr(self.expert_tools, tool_name) or hasattr(self.extended_tools, tool_name):
                console.print(f"[bold green]ğŸ”§ Executing Tool:[/bold green] {tool_name}")
```

**Ù…Ø§ ÙŠØ­Ø¯Ø«**:
- ÙŠØªØ­Ù‚Ù‚ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø£Ø¯Ø§Ø© Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ:
  - `self.tools` (Ø§Ù„Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©)
  - `self.expert_tools` (Ø§Ù„Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ù…ØªØ®ØµØµØ©)
  - `self.extended_tools` (Ø§Ù„Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ø¥Ø¶Ø§ÙÙŠØ©)

---

### Ø§Ù„Ù…Ø±Ø­Ù„Ø© 6: ØªÙ†ÙÙŠØ° Ø§Ù„Ø£Ø¯ÙˆØ§Øª (Tool Execution)

**Ø§Ù„Ù…Ù„Ù**: `src/agents/expert_agent.py` - Ø¯Ø§Ù„Ø© `run()` (Tool Execution Section)

#### 6.1 ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù€ Args

```python
                # Convert args list to params dict based on tool signature
                params = {}
                try:
                    if tool_name == "write_file":
                        # args: [filepath, content]
                        if len(args_list) >= 2:
                            params["filepath"] = args_list[0]
                            params["content"] = args_list[1]
                        elif len(args_list) == 1:
                            params["filepath"] = args_list[0]
                            params["content"] = ""
                    
                    elif tool_name == "create_directory":
                        # args: [dirpath]
                        if args_list:
                            params["dirpath"] = args_list[0]
```

**Ù…Ø«Ø§Ù„**:
```python
# Ù…Ù† Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„:
{"tool": "write_file", "args": ["math_calculator/calc.py", "def add()..."]}

# Ø¥Ù„Ù‰:
params = {
    "filepath": "math_calculator/calc.py",
    "content": "def add()..."
}
```

**Ù…Ø§ ÙŠØ­Ø¯Ø«**:
- ÙŠØ­ÙˆÙ„ args list Ø¥Ù„Ù‰ params dict Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ ØªÙˆÙ‚ÙŠØ¹ Ø§Ù„Ø£Ø¯Ø§Ø©

#### 6.2 ØªÙ†ÙÙŠØ° Ø§Ù„Ø£Ø¯Ø§Ø©

```python
                    # Execute the tool
                    if hasattr(self.tools, tool_name):
                        tool_func = getattr(self.tools, tool_name)
                        result = tool_func(**params)
                    elif hasattr(self.expert_tools, tool_name):
                        tool_func = getattr(self.expert_tools, tool_name)
                        result = tool_func(**params)
                    elif hasattr(self.extended_tools, tool_name):
                        tool_func = getattr(self.extended_tools, tool_name)
                        result = tool_func(**params)
                    else:
                        result = f"Error: Tool {tool_name} not found"
                    
                    # Show what the tool is doing
                    if "learn" in tool_name.lower():
                        console.print(f"[dim]ğŸ’¡ Action: Learning and saving knowledge...[/dim]")
                    elif "search" in tool_name.lower():
                        console.print(f"[dim]ğŸ” Action: Searching for information...[/dim]")
                    elif "read" in tool_name.lower():
                        console.print(f"[dim]ğŸ“– Action: Reading from knowledge base...[/dim]")
                    elif "save" in tool_name.lower() or "update" in tool_name.lower():
                        console.print(f"[dim]ğŸ’¾ Action: Saving/updating knowledge...[/dim]")
                    
                    console.print(f"[green]âœ… Tool Result:[/green] {result[:200]}...")
                    final_response += f"\n\nTool: {tool_name}\nResult: {result}"
                    tool_executed = True
                    tools_executed_count += 1
```

**Ù…Ø§ ÙŠØ­Ø¯Ø«**:
- ÙŠØ³ØªØ¯Ø¹ÙŠ Ø§Ù„Ø£Ø¯Ø§Ø©: `tool_instance.tool_name(**params)`
- ÙŠØ¹Ø±Ø¶ Ø±Ø³Ø§Ù„Ø© ØªÙ‚Ø¯Ù…ÙŠØ© (Progress message)
- ÙŠØ¬Ù…Ø¹ Ø§Ù„Ù†ØªÙŠØ¬Ø©

#### 6.3 Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ø®Ø·Ø§Ø¡

```python
                except Exception as e:
                    error_msg = f"Error executing {tool_name}: {str(e)}"
                    console.print(f"[red]{error_msg}[/red]")
                    final_response += f"\n\nError: {error_msg}"
                    continue
```

**Ù…Ø§ ÙŠØ­Ø¯Ø«**:
- Ø¥Ø°Ø§ ÙØ´Ù„Øª Ø§Ù„Ø£Ø¯Ø§Ø©ØŒ ÙŠØ¹Ø±Ø¶ Ø±Ø³Ø§Ù„Ø© Ø®Ø·Ø£
- ÙŠØ­Ø§ÙˆÙ„ Ø§Ù„Ø§Ø³ØªÙ…Ø±Ø§Ø± Ù…Ø¹ Ø£Ø¯ÙˆØ§Øª Ø£Ø®Ø±Ù‰

#### 6.4 Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªÙŠØ¬Ø©

```python
        # Display final response
        if final_response:
            console.print(Panel(
                Markdown(final_response),
                title="âœ… Expert Response",
                border_style="green"
            ))
        
        # Save to memory
        if tool_executed:
            self.memory.save_solution(user_input, final_response, rating=5)
```

**Ù…Ø§ ÙŠØ­Ø¯Ø«**:
- ÙŠØ¹Ø±Ø¶ Ø§Ù„Ù†ØªÙŠØ¬Ø© ÙÙŠ Panel
- ÙŠØ­ÙØ¸ ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø© (Memory) Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠ

---

### Ø§Ù„Ù…Ø±Ø­Ù„Ø© 7: Ø­Ù„Ù‚Ø© ReAct (Reasoning + Acting)

**Ø§Ù„Ù…Ù„Ù**: `src/agents/expert_agent.py` - Ø¯Ø§Ù„Ø© `run()` (ReAct Loop)

Ø§Ù„Ø­Ù„Ù‚Ø© ØªØ¹Ù…Ù„ ÙƒØ§Ù„ØªØ§Ù„ÙŠ:

```
1. Think: Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ÙŠÙÙƒØ± ÙÙŠ Ø§Ù„Ø­Ù„
2. Act: ÙŠÙ‚Ø±Ø± Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø£Ø¯Ø§Ø© Ù…Ø¹ÙŠÙ†Ø©
3. Observe: ÙŠØ±Ù‰ Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø£Ø¯Ø§Ø©
4. Think Again: ÙŠÙÙƒØ± ÙÙŠ Ø§Ù„Ø®Ø·ÙˆØ© Ø§Ù„ØªØ§Ù„ÙŠØ©
5. Repeat: Ø­ØªÙ‰ ÙŠÙƒØªÙ…Ù„ Ø§Ù„Ø­Ù„ Ø£Ùˆ ÙŠØµÙ„ Ù„Ù€ max_iterations
```

**Ù…Ø«Ø§Ù„ Ø¹Ù…Ù„ÙŠ**:

```
User: "Create math calculator using Python"

Iteration 1:
  Think: "I need to create a calculator. First, I should create a directory."
  Act: create_directory("math_calculator")
  Observe: Directory created successfully

Iteration 2:
  Think: "Now I need to create the calculator.py file with functions."
  Act: write_file("math_calculator/calculator.py", "def add()...")
  Observe: File created successfully

Iteration 3:
  Think: "I should also create a README file."
  Act: write_file("math_calculator/README.md", "...")
  Observe: File created successfully

Final: "Calculator project created successfully!"
```

**Ø§Ù„ØªÙ†ÙÙŠØ° ÙÙŠ Ø§Ù„ÙƒÙˆØ¯**:

```python
        # ReAct Loop (can be extended for multiple iterations)
        iteration = 0
        max_iterations = self.max_iterations
        
        while iteration < max_iterations:
            # Check if we have tool calls to execute
            if json_tool_calls:
                # Execute tools (already done above)
                break
            
            # If no tool calls, check if response is complete
            if "complete" in response.lower() or "done" in response.lower():
                break
            
            iteration += 1
```

---

## Ù†Ø¸Ø§Ù… Ø§Ù„Ø£Ø¯ÙˆØ§Øª (Tools System)

### 1. Ø§Ù„Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© (22 Ø£Ø¯Ø§Ø©)

**Ø§Ù„Ù…Ù„Ù**: `src/tools/tools.py`

**Ø§Ù„ÙØ¦Ø§Øª**:

- **Ù…Ù„ÙØ§Øª**: read_file, write_file, list_directory, search_files, delete_file
- **Ø£ÙˆØ§Ù…Ø±**: run_command
- **ÙˆÙŠØ¨**: search_web, scrape_webpage, fetch_api
- **Ù†Ø¸Ø§Ù…**: get_system_info, monitor_resources, check_service
- **Docker**: docker_command
- **Ø£Ù…Ø§Ù†**: scan_ports, check_ssl

### 2. Ø§Ù„Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ù…ØªØ®ØµØµØ© (45+ Ø£Ø¯Ø§Ø©)

**Ø§Ù„Ù…Ù„Ù**: `src/tools/expert_tools.py`

**Ø§Ù„ÙØ¦Ø§Øª**:

- **Ø¨Ø±Ù…Ø¬Ø©**: create_python_project, generate_code, analyze_code
- **Ù…ÙˆØ§Ù‚Ø¹**: create_html_template, generate_css, create_react_component
- **Ø³ÙŠØ±ÙØ±Ø§Øª**: check_server_health, manage_nginx, setup_ssl
- **Docker**: create_dockerfile, docker_compose_generate, docker_build
- **PostgreSQL**: postgres_query, postgres_backup, postgres_create_table
- **n8n**: create_n8n_workflow, n8n_api_call, export_n8n_workflow
- **ØªØ¹Ù„Ù…**: search_documentation, learn_new_technology, save_code_snippet

### 3. Ø¢Ù„ÙŠØ© ØªÙ†ÙÙŠØ° Ø§Ù„Ø£Ø¯Ø§Ø©

ÙƒÙ„ Ø£Ø¯Ø§Ø© Ù‡ÙŠ Ø¯Ø§Ù„Ø© Python Ø¹Ø§Ø¯ÙŠØ©:

```python
def write_file(self, filepath: str, content: str) -> str:
    """Write content to a file"""
    try:
        path = Path(filepath)
        path.parent.mkdir(parents=True, exist_ok=True)
        path.write_text(content, encoding='utf-8')
        return f"File written successfully: {filepath}"
    except Exception as e:
        return f"Error: {str(e)}"
```

**ÙƒÙŠÙ ÙŠØªÙ… Ø§Ø³ØªØ¯Ø¹Ø§Ø¤Ù‡Ø§**:

```python
# Ù…Ù† Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„:
{"tool": "write_file", "args": ["test.py", "print('hello')"]}

# ÙÙŠ Ø§Ù„ÙƒÙˆØ¯:
tool_func = getattr(self.tools, "write_file")
result = tool_func(filepath="test.py", content="print('hello')")
```

---

## Ù†Ø¸Ø§Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø© (Memory System)

**Ø§Ù„Ù…Ù„Ù**: `src/core/memory.py`

### 1. Ø§Ù„ØªØ®Ø²ÙŠÙ†

```python
def save_solution(self, task: str, solution: str, rating: int = 5):
    """Save a solution to memory"""
    try:
        self.conn.execute(
            "INSERT INTO memory (task, solution, rating, timestamp) VALUES (?, ?, ?, ?)",
            (task, solution, rating, datetime.now().isoformat())
        )
        self.conn.commit()
    except Exception as e:
        print(f"Error saving to memory: {e}")
```

**Ù…Ø§ ÙŠØ­Ø¯Ø«**:
- ÙŠØ³ØªØ®Ø¯Ù… SQLite database (`data/agent_memory.db`)
- ÙŠØ­ÙØ¸:
  - Ø§Ù„Ù…Ù‡Ù…Ø© (task)
  - Ø§Ù„Ø­Ù„ (solution)
  - Ø§Ù„ØªÙ‚ÙŠÙŠÙ… (rating)
  - Ø§Ù„ØªØ§Ø±ÙŠØ® (timestamp)

### 2. Ø§Ù„Ø§Ø³ØªØ±Ø¬Ø§Ø¹

```python
def search_similar(self, query: str, limit: int = 5) -> List[Tuple[str, int]]:
    """Search for similar past solutions"""
    try:
        cursor = self.conn.execute(
            "SELECT solution, rating FROM memory WHERE task LIKE ? ORDER BY rating DESC, timestamp DESC LIMIT ?",
            (f"%{query}%", limit)
        )
        return [(row[0], row[1]) for row in cursor.fetchall()]
    except Exception as e:
        print(f"Error searching memory: {e}")
        return []
```

**Ù…Ø§ ÙŠØ­Ø¯Ø«**:
- Ø¹Ù†Ø¯ Ø·Ù„Ø¨ Ø¬Ø¯ÙŠØ¯ØŒ ÙŠØ¨Ø­Ø« ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø¹Ù† Ø­Ù„ÙˆÙ„ Ù…Ø´Ø§Ø¨Ù‡Ø©
- ÙŠØ³ØªØ®Ø¯Ù… semantic search (Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ)
- ÙŠØ¹Ø±Ø¶ Ø§Ù„Ø­Ù„ Ø§Ù„Ø³Ø§Ø¨Ù‚ Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…

---

## Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ (Auto Learning)

**Ø§Ù„Ù…Ù„Ù**: `src/tools/auto_learner.py`

### 1. Ø¢Ù„ÙŠØ© Ø§Ù„ØªØ¹Ù„Ù…

#### 1.1 Ù‚Ø±Ø§Ø¡Ø© Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø£Ø¯ÙˆØ§Øª

```python
def load_tools_list(self) -> Dict[str, List[str]]:
    """Load the master list of tools to learn"""
    if not self.tools_file.exists():
        return {}
    
    try:
        content = self.tools_file.read_text(encoding='utf-8')
        content = content.lstrip('\ufeff').strip()
        return json.loads(content)
    except json.JSONDecodeError as e:
        return {}
```

**Ù…Ø§ ÙŠØ­Ø¯Ø«**:
- ÙŠÙ‚Ø±Ø£ `data/essential_tools.json`
- ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø¬Ù…ÙŠØ¹ Ø§Ù„ØªÙ‚Ù†ÙŠØ§Øª Ø§Ù„Ù…Ø±Ø§Ø¯ ØªØ¹Ù„Ù…Ù‡Ø§

#### 1.2 Ø§Ù„ØªØ¹Ù„Ù… Ù„ÙƒÙ„ ØªÙ‚Ù†ÙŠØ©

```python
def learn_all(self):
    """Learn EVERYTHING in the list automatically"""
    categories = self.load_tools_list()
    learned = self.load_progress()
    
    for category, tools in categories.items():
        for tool in tools:
            if tool in learned:
                continue
            
            # 1. Fast Learn
            try:
                topics = ["overview", "key-features", "installation", "best-practices"]
                
                # Custom topics based on category
                if category == "data_analysis":
                    topics.extend(["data-structures", "visualization", "analysis-examples"])
                elif category == "databases":
                    topics.extend(["crud-operations", "connection-setup", "query-examples"])
                # ... more categories
                
                # Execute learning
                results = self.fast_learner.learn_fast(tool, topics)
                
                # 2. Save to Knowledge Base
                self.fast_learner.save_to_knowledge_base(results)
                
                # 3. Mark as done
                self.save_progress(tool)
                
            except Exception as e:
                print(f"âŒ Failed to learn {tool}: {e}")
                continue
```

**Ù…Ø§ ÙŠØ­Ø¯Ø«**:
- ÙŠØ³ØªØ®Ø¯Ù… `FastLearning` Ù„ØªØ¹Ù„Ù… ÙƒÙ„ ØªÙ‚Ù†ÙŠØ©
- ÙŠØ¨Ø­Ø« ÙÙŠ Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª Ø¹Ù† Ù…Ø¹Ù„ÙˆÙ…Ø§Øª
- ÙŠØ­ÙØ¸ ÙÙŠ `data/knowledge_base/`

#### 1.3 Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø¯Ù…

```python
def save_progress(self, learned_tool: str):
    """Mark a tool as learned"""
    progress = self.load_progress()
    if learned_tool not in progress:
        progress.append(learned_tool)
        try:
            self.progress_file.write_text(
                json.dumps(progress, indent=2, ensure_ascii=False),
                encoding='utf-8'
            )
        except Exception as e:
            print(f"WARNING: Failed to save progress: {e}")
```

**Ù…Ø§ ÙŠØ­Ø¯Ø«**:
- ÙŠØ­ÙØ¸ ÙÙŠ `data/learning_progress.json`
- ÙŠØªØ®Ø·Ù‰ Ø§Ù„ØªÙ‚Ù†ÙŠØ§Øª Ø§Ù„ØªÙŠ ØªÙ… ØªØ¹Ù„Ù…Ù‡Ø§ Ù…Ø³Ø¨Ù‚Ø§Ù‹

### 2. Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø¹Ø±ÙØ©

```python
def read_knowledge_base(self, technology: str) -> str:
    """Read knowledge from knowledge base"""
    kb_dir = get_knowledge_base_dir()
    tech_dir = kb_dir / technology.lower().replace(' ', '_')
    
    if not tech_dir.exists():
        return f"Knowledge base not found for {technology}"
    
    # Read all markdown files
    content = ""
    for md_file in tech_dir.glob("*.md"):
        content += md_file.read_text(encoding='utf-8') + "\n\n"
    
    return content if content else f"No knowledge found for {technology}"
```

**Ù…Ø§ ÙŠØ­Ø¯Ø«**:
- Ø¹Ù†Ø¯ Ø§Ù„Ø­Ø§Ø¬Ø©ØŒ ÙŠÙ‚Ø±Ø£ Ù…Ù† `knowledge_base/`
- ÙŠØ³ØªØ®Ø¯Ù… Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø© Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø£ÙˆÙ†Ù„Ø§ÙŠÙ†

---

## Ù…Ø«Ø§Ù„ ÙƒØ§Ù…Ù„: Ø¥Ù†Ø´Ø§Ø¡ Math Calculator

Ø¹Ù†Ø¯Ù…Ø§ ÙŠØ·Ù„Ø¨ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: "Create math calculator using Python"

### Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø§Ù„ØªÙØµÙŠÙ„ÙŠØ©:

#### 1. Task Detection

```python
task_description = "Create math calculator using Python"
task_lower = task_description.lower()
# Ø§Ù„ÙƒÙ„Ù…Ø§Øª: "create", "calculator", "python"
# Ø§Ù„Ù†ÙˆØ¹: 'coding' (Ù„Ø£Ù† "python" ÙÙŠ Ù‚Ø§Ø¦Ù…Ø© coding keywords)
```

#### 2. Model Selection

```python
scores = {
    "deepseek-r1:8b": 130,  # 100 (coding) + 30 (size > 4GB)
    "mistral:latest": 75,
    "qwen2.5:3b": 50
}
# Ø§Ù„Ù…Ø®ØªØ§Ø±: "deepseek-r1:8b"
```

#### 3. Prompt Building

```python
prompt = """You are an Expert AI Agent with access to powerful tools.

Available Tools:
- create_directory(dirpath): Create a directory
- write_file(filepath, content): Write content to a file
- create_python_project(project_name, options): Create Python project
...

Task: Create math calculator using Python

Instructions:
1. Analyze the task
2. Plan your approach
3. Use appropriate tools
4. Provide final answer

Start by thinking about the task, then use tools as needed.
"""
```

#### 4. Model Call

```python
response = requests.post(
    "http://localhost:11434/api/generate",
    json={
        "model": "deepseek-r1:8b",
        "prompt": prompt,
        "stream": True
    }
)
# ÙŠØ³ØªÙ‚Ø¨Ù„ Ø±Ø¯ Ù…ØªØ¯ÙÙ‚
```

#### 5. Tool Calls Extraction

Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ÙŠØ±Ø¯ Ø¨Ù€:

```json
{
  "tool": "create_directory",
  "args": ["math_calculator"]
}
```

Ø«Ù…:

```json
{
  "tool": "write_file",
  "args": [
    "math_calculator/calculator.py",
    "def add(a, b):\n    return a + b\n\ndef subtract(a, b):\n    return a - b\n..."
  ]
}
```

#### 6. Tool Execution

```python
# ØªÙ†ÙÙŠØ° create_directory
result1 = self.tools.create_directory("math_calculator")
# Output: "Directory created: math_calculator"

# ØªÙ†ÙÙŠØ° write_file
result2 = self.tools.write_file(
    "math_calculator/calculator.py",
    "def add(a, b):\n    return a + b\n..."
)
# Output: "File written successfully: math_calculator/calculator.py"

# ØªÙ†ÙÙŠØ° write_file Ù„Ù„Ù€ README
result3 = self.tools.write_file(
    "math_calculator/README.md",
    "# Math Calculator\n\nA simple calculator..."
)
# Output: "File written successfully: math_calculator/README.md"
```

#### 7. Response

```python
final_response = """
âœ… Calculator project created successfully!

Created files:
- math_calculator/calculator.py (main calculator code)
- math_calculator/README.md (documentation)

To run:
cd math_calculator
python calculator.py
"""
```

---

## Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© ÙˆØ§Ù„Ù…Ø³Ø¤ÙˆÙ„ÙŠØ§Øª

| Ø§Ù„Ù…Ù„Ù | Ø§Ù„Ù…Ø³Ø¤ÙˆÙ„ÙŠØ© |
|-------|-----------|
| `src/agents/expert_agent.py` | Ø§Ù„Ù€ Agent Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØŒ ReAct loopØŒ Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ |
| `src/tools/tools.py` | 22 Ø£Ø¯Ø§Ø© Ø£Ø³Ø§Ø³ÙŠØ© (Ù…Ù„ÙØ§ØªØŒ Ø£ÙˆØ§Ù…Ø±ØŒ ÙˆÙŠØ¨) |
| `src/tools/expert_tools.py` | 45+ Ø£Ø¯Ø§Ø© Ù…ØªØ®ØµØµØ© (Ø¨Ø±Ù…Ø¬Ø©ØŒ DockerØŒ PostgreSQL) |
| `src/core/memory.py` | Ù†Ø¸Ø§Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø© SQLite |
| `src/tools/auto_learner.py` | Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ Ù„Ù„ØªÙ‚Ù†ÙŠØ§Øª |
| `src/tools/fast_learning.py` | Ø§Ù„Ø¨Ø­Ø« ÙˆØ§Ù„ØªØ¹Ù„Ù… Ù…Ù† Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª |
| `config.py` | Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ ÙˆØ§Ù„Ù…Ø³Ø§Ø±Ø§Øª |

---

## Ø§Ù„Ø®Ù„Ø§ØµØ©

Ø§Ù„Ù†Ø¸Ø§Ù… ÙŠØ¹Ù…Ù„ ÙƒØ§Ù„ØªØ§Ù„ÙŠ:

1. **ÙŠØ³ØªÙ‚Ø¨Ù„ Ø§Ù„Ø·Ù„Ø¨** Ù…Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
2. **ÙŠÙƒØ´Ù Ù†ÙˆØ¹ Ø§Ù„Ù…Ù‡Ù…Ø©** ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹
3. **ÙŠØ®ØªØ§Ø± Ø£ÙØ¶Ù„ Ù…ÙˆØ¯ÙŠÙ„** Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù†ÙˆØ¹ Ø§Ù„Ù…Ù‡Ù…Ø©
4. **ÙŠØ¨Ù†ÙŠ prompt** ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¯ÙˆØ§Øª ÙˆØ§Ù„Ø³ÙŠØ§Ù‚
5. **ÙŠØ³ØªØ¯Ø¹ÙŠ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„** Ø¹Ø¨Ø± Ollama API
6. **ÙŠØ³ØªØ®Ø±Ø¬ Tool Calls** Ù…Ù† Ø±Ø¯ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„
7. **ÙŠÙ†ÙØ° Ø§Ù„Ø£Ø¯ÙˆØ§Øª** Ø¨Ø§Ù„ØªØ±ØªÙŠØ¨
8. **ÙŠØ¹Ø±Ø¶ Ø§Ù„Ù†ØªÙŠØ¬Ø©** ÙˆÙŠØ­ÙØ¸ ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø©

Ø§Ù„Ù†Ø¸Ø§Ù… Ù…ØµÙ…Ù… Ù„ÙŠÙƒÙˆÙ†:

- **Ø°ÙƒÙŠ**: ÙŠØ®ØªØ§Ø± Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹
- **Ù…Ø±Ù†**: 67+ Ø£Ø¯Ø§Ø© Ù„Ù…Ù‡Ø§Ù… Ù…Ø®ØªÙ„ÙØ©
- **Ù‚Ø§Ø¨Ù„ Ù„Ù„ØªØ¹Ù„Ù…**: ÙŠØ­ÙØ¸ Ø§Ù„Ø­Ù„ÙˆÙ„ ÙˆÙŠØ³ØªØ®Ø¯Ù…Ù‡Ø§ Ù„Ø§Ø­Ù‚Ø§Ù‹
- **Ù…Ø­Ù„ÙŠ**: ÙŠØ¹Ù…Ù„ Ø¨Ø¯ÙˆÙ† API keysØŒ ÙƒÙ„ Ø´ÙŠØ¡ Ø¹Ù„Ù‰ Ø§Ù„Ø³ÙŠØ±ÙØ± Ø§Ù„Ù…Ø­Ù„ÙŠ

---

## Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©

### Ù„Ù…Ø§Ø°Ø§ Ø§Ù„Ù†Ø¸Ø§Ù… Ø¨Ø·ÙŠØ¡ Ø£Ø­ÙŠØ§Ù†Ø§Ù‹ØŸ

1. **Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„Ø§Øª Ø§Ù„ÙƒØ¨ÙŠØ±Ø©**: Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„Ø§Øª Ø§Ù„ÙƒØ¨ÙŠØ±Ø© (Ù…Ø«Ù„ deepseek-r1:8b) ØªØ­ØªØ§Ø¬ ÙˆÙ‚Øª Ø£Ø·ÙˆÙ„ Ù„Ù„ØªÙÙƒÙŠØ±
2. **Streaming**: Ø§Ù„Ù†Ø¸Ø§Ù… ÙŠØ³ØªÙ‚Ø¨Ù„ Ø§Ù„Ø±Ø¯ token Ø¨Ø¹Ø¯ tokenØŒ Ù…Ù…Ø§ ÙŠØ²ÙŠØ¯ Ø§Ù„ÙˆÙ‚Øª
3. **Tool Execution**: ØªÙ†ÙÙŠØ° Ø§Ù„Ø£Ø¯ÙˆØ§Øª Ù‚Ø¯ ÙŠØ³ØªØºØ±Ù‚ ÙˆÙ‚ØªØ§Ù‹ (Ù…Ø«Ù„ Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª)

### ÙƒÙŠÙ ØªØ­Ø³Ù† Ø§Ù„Ø£Ø¯Ø§Ø¡ØŸ

1. **Ø§Ø³ØªØ®Ø¯Ù… Ù…ÙˆØ¯ÙŠÙ„Ø§Øª Ø£ØµØºØ±**: Ù„Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ø¨Ø³ÙŠØ·Ø©ØŒ Ø§Ø³ØªØ®Ø¯Ù… qwen2.5:3b
2. **Ø­Ø¯Ø¯ Ù†ÙˆØ¹ Ø§Ù„Ù…Ù‡Ù…Ø©**: Ø¥Ø°Ø§ Ø­Ø¯Ø¯Øª `task_type` ÙŠØ¯ÙˆÙŠØ§Ù‹ØŒ ÙŠÙˆÙØ± ÙˆÙ‚Øª Ø§Ù„ÙƒØ´Ù
3. **Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø©**: Ø§Ù„Ù†Ø¸Ø§Ù… ÙŠØ­ÙØ¸ Ø§Ù„Ø­Ù„ÙˆÙ„ØŒ Ø§Ø³ØªØ®Ø¯Ù…Ù‡Ø§ Ù„ØªØ¬Ù†Ø¨ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ø­Ø³Ø§Ø¨

### Ù†ØµØ§Ø¦Ø­ Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…

1. **ÙƒÙ† Ù…Ø­Ø¯Ø¯Ø§Ù‹**: ÙƒÙ„Ù…Ø§ ÙƒØ§Ù† Ø§Ù„Ø·Ù„Ø¨ Ø£ÙˆØ¶Ø­ØŒ ÙƒÙ„Ù…Ø§ ÙƒØ§Ù† Ø§Ù„Ø­Ù„ Ø£ÙØ¶Ù„
2. **Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©**: Ø§Ø³ØªØ®Ø¯Ù… ÙƒÙ„Ù…Ø§Øª Ù…Ø«Ù„ "python", "docker", "database" Ù„ØªÙˆØ¬ÙŠÙ‡ Ø§Ù„Ù†Ø¸Ø§Ù…
3. **Ø±Ø§Ø¬Ø¹ Ø§Ù„Ù†ØªØ§Ø¦Ø¬**: Ø¯Ø§Ø¦Ù…Ø§Ù‹ Ø±Ø§Ø¬Ø¹ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ù†Ø´Ø£Ø© Ù‚Ø¨Ù„ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…

---

**ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù‡Ø°Ø§ Ø§Ù„Ø¯Ù„ÙŠÙ„ Ø¨ÙˆØ§Ø³Ø·Ø©**: AI Agent System Documentation  
**Ø§Ù„ØªØ§Ø±ÙŠØ®**: 2025-01-27  
**Ø§Ù„Ø¥ØµØ¯Ø§Ø±**: 1.0.0

